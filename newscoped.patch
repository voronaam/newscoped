diff -r 8fd684b8c649 src/cpu/x86/vm/templateTable_x86.cpp
--- a/src/cpu/x86/vm/templateTable_x86.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/cpu/x86/vm/templateTable_x86.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -3956,6 +3956,10 @@
   __ bind(done);
 }
 
+void TemplateTable::newscoped() {
+    TemplateTable::_new();
+}
+
 void TemplateTable::newarray() {
   transition(itos, atos);
   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
diff -r 8fd684b8c649 src/share/vm/classfile/verifier.cpp
--- a/src/share/vm/classfile/verifier.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/classfile/verifier.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -1613,6 +1613,7 @@
             &bcs, code_length, &current_frame, (bci >= ex_min && bci < ex_max),
             &this_uninit, return_type, cp, &stackmap_table, CHECK_VERIFY(this));
           no_control_flow = false; break;
+        case Bytecodes::_newscoped :
         case Bytecodes::_new :
         {
           index = bcs.get_index_u2();
@@ -2530,7 +2531,7 @@
   } else if (type.is_uninitialized()) {
     u2 new_offset = type.bci();
     address new_bcp = bcs->bcp() - bci + new_offset;
-    if (new_offset > (code_length - 3) || (*new_bcp) != Bytecodes::_new) {
+    if (new_offset > (code_length - 3) || ((*new_bcp) != Bytecodes::_new && (*new_bcp) != Bytecodes::_newscoped)) {
       /* Unreachable?  Stack map parsing ensures valid type and new
        * instructions have a valid BCI. */
       verify_error(ErrorContext::bad_code(new_offset),
diff -r 8fd684b8c649 src/share/vm/interpreter/bytecode.hpp
--- a/src/share/vm/interpreter/bytecode.hpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/bytecode.hpp	Mon Nov 16 01:14:43 2015 +0000
@@ -290,6 +290,15 @@
   long index() const   { return get_index_u2(Bytecodes::_new); };
 };
 
+class Bytecode_newscoped: public Bytecode {
+ public:
+  Bytecode_newscoped(Method* method, address bcp): Bytecode(method, bcp) { verify(); }
+  void verify() const { assert(java_code() == Bytecodes::_newscoped, "check new"); }
+
+  // Returns index
+  long index() const   { return get_index_u2(Bytecodes::_newscoped); };
+};
+
 class Bytecode_multianewarray: public Bytecode {
  public:
   Bytecode_multianewarray(Method* method, address bcp): Bytecode(method, bcp) { verify(); }
diff -r 8fd684b8c649 src/share/vm/interpreter/bytecodeInterpreter.cpp
--- a/src/share/vm/interpreter/bytecodeInterpreter.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/bytecodeInterpreter.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -568,7 +568,7 @@
 
 /* 0xC0 */ &&opc_checkcast,   &&opc_instanceof,     &&opc_monitorenter, &&opc_monitorexit,
 /* 0xC4 */ &&opc_wide,        &&opc_multianewarray, &&opc_ifnull,       &&opc_ifnonnull,
-/* 0xC8 */ &&opc_goto_w,      &&opc_jsr_w,          &&opc_breakpoint,   &&opc_default,
+/* 0xC8 */ &&opc_goto_w,      &&opc_jsr_w,          &&opc_breakpoint,   &&opc_newscoped,
 /* 0xCC */ &&opc_default,     &&opc_default,        &&opc_default,      &&opc_default,
 
 /* 0xD0 */ &&opc_default,     &&opc_default,        &&opc_default,      &&opc_default,
@@ -2212,6 +2212,77 @@
         THREAD->set_vm_result(NULL);
         UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
       }
+
+      CASE(_newscoped): {
+        u2 index = Bytes::get_Java_u2(pc+1);
+        ConstantPool* constants = istate->method()->constants();
+        if (!constants->tag_at(index).is_unresolved_klass()) {
+          // Make sure klass is initialized and doesn't have a finalizer
+          Klass* entry = constants->slot_at(index).get_klass();
+          assert(entry->is_klass(), "Should be resolved klass");
+          Klass* k_entry = (Klass*) entry;
+          assert(k_entry->oop_is_instance(), "Should be InstanceKlass");
+          InstanceKlass* ik = (InstanceKlass*) k_entry;
+          if ( ik->is_initialized() && ik->can_be_fastpath_allocated() ) {
+            size_t obj_size = ik->size_helper();
+            oop result = NULL;
+            // If the TLAB isn't pre-zeroed then we'll have to do it
+            bool need_zero = !ZeroTLAB;
+            if (UseTLAB) {
+              result = (oop) THREAD->tlab().allocate(obj_size);
+            }
+            // Disable non-TLAB-based fast-path, because profiling requires that all
+            // allocations go through InterpreterRuntime::_new() if THREAD->tlab().allocate
+            // returns NULL.
+#ifndef CC_INTERP_PROFILE
+            if (result == NULL) {
+              need_zero = true;
+              // Try allocate in shared eden
+            retry:
+              HeapWord* compare_to = *Universe::heap()->top_addr();
+              HeapWord* new_top = compare_to + obj_size;
+              if (new_top <= *Universe::heap()->end_addr()) {
+                if (Atomic::cmpxchg_ptr(new_top, Universe::heap()->top_addr(), compare_to) != compare_to) {
+                  goto retry;
+                }
+                result = (oop) compare_to;
+              }
+            }
+#endif
+            if (result != NULL) {
+              // Initialize object (if nonzero size and need) and then the header
+              if (need_zero ) {
+                HeapWord* to_zero = (HeapWord*) result + sizeof(oopDesc) / oopSize;
+                obj_size -= sizeof(oopDesc) / oopSize;
+                if (obj_size > 0 ) {
+                  memset(to_zero, 0, obj_size * HeapWordSize);
+                }
+              }
+              if (UseBiasedLocking) {
+                result->set_mark(ik->prototype_header());
+              } else {
+                result->set_mark(markOopDesc::prototype());
+              }
+              result->set_klass_gap(0);
+              result->set_klass(k_entry);
+              // Must prevent reordering of stores for object initialization
+              // with stores that publish the new object.
+              OrderAccess::storestore();
+              SET_STACK_OBJECT(result, 0);
+              UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
+            }
+          }
+        }
+        // Slow case allocation
+        CALL_VM(InterpreterRuntime::newscoped(THREAD, METHOD->constants(), index),
+                handle_exception);
+        // Must prevent reordering of stores for object initialization
+        // with stores that publish the new object.
+        OrderAccess::storestore();
+        SET_STACK_OBJECT(THREAD->vm_result(), 0);
+        THREAD->set_vm_result(NULL);
+        UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
+      }
       CASE(_anewarray): {
         u2 index = Bytes::get_Java_u2(pc+1);
         jint size = STACK_INT(-1);
diff -r 8fd684b8c649 src/share/vm/interpreter/bytecodeTracer.cpp
--- a/src/share/vm/interpreter/bytecodeTracer.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/bytecodeTracer.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -575,6 +575,7 @@
       break;
 
     case Bytecodes::_new:
+    case Bytecodes::_newscoped:
     case Bytecodes::_checkcast:
     case Bytecodes::_instanceof:
       { int i = get_index_u2();
diff -r 8fd684b8c649 src/share/vm/interpreter/bytecodes.cpp
--- a/src/share/vm/interpreter/bytecodes.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/bytecodes.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -481,6 +481,7 @@
   def(_goto_w              , "goto_w"              , "boooo", NULL    , T_VOID   ,  0, false);
   def(_jsr_w               , "jsr_w"               , "boooo", NULL    , T_INT    ,  0, false);
   def(_breakpoint          , "breakpoint"          , ""     , NULL    , T_VOID   ,  0, true);
+  def(_newscoped           , "newscoped"           , "bkk"  , NULL    , T_OBJECT ,  1, true );
 
   //  JVM bytecodes
   //  bytecode               bytecode name           format   wide f.   result tp  stk traps  std code
diff -r 8fd684b8c649 src/share/vm/interpreter/bytecodes.hpp
--- a/src/share/vm/interpreter/bytecodes.hpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/bytecodes.hpp	Mon Nov 16 01:14:43 2015 +0000
@@ -241,6 +241,7 @@
     _goto_w               = 200, // 0xc8
     _jsr_w                = 201, // 0xc9
     _breakpoint           = 202, // 0xca
+    _newscoped            = 203, // 0xcb
 
     number_of_java_codes,
 
diff -r 8fd684b8c649 src/share/vm/interpreter/interpreterRuntime.cpp
--- a/src/share/vm/interpreter/interpreterRuntime.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/interpreterRuntime.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -164,6 +164,34 @@
   thread->set_vm_result(obj);
 IRT_END
 
+IRT_ENTRY(void, InterpreterRuntime::newscoped(JavaThread* thread, ConstantPool* pool, int index))
+  Klass* k_oop = pool->klass_at(index, CHECK);
+  instanceKlassHandle klass (THREAD, k_oop);
+
+  // Make sure we are not instantiating an abstract klass
+  klass->check_valid_for_instantiation(true, CHECK);
+
+  // Make sure klass is initialized
+  klass->initialize(CHECK);
+
+  // At this point the class may not be fully initialized
+  // because of recursive initialization. If it is fully
+  // initialized & has_finalized is not set, we rewrite
+  // it into its fast version (Note: no locking is needed
+  // here since this is an atomic byte write and can be
+  // done more than once).
+  //
+  // Note: In case of classes with has_finalized we don't
+  //       rewrite since that saves us an extra check in
+  //       the fast version which then would call the
+  //       slow version anyway (and do a call back into
+  //       Java).
+  //       If we have a breakpoint, then we don't rewrite
+  //       because the _breakpoint bytecode would be lost.
+  oop obj = klass->allocate_instance(CHECK);
+  thread->set_vm_result(obj);
+IRT_END
+
 
 IRT_ENTRY(void, InterpreterRuntime::newarray(JavaThread* thread, BasicType type, jint size))
   oop obj = oopFactory::new_typeArray(type, size, CHECK);
diff -r 8fd684b8c649 src/share/vm/interpreter/interpreterRuntime.hpp
--- a/src/share/vm/interpreter/interpreterRuntime.hpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/interpreterRuntime.hpp	Mon Nov 16 01:14:43 2015 +0000
@@ -83,6 +83,7 @@
 
   // Allocation
   static void    _new          (JavaThread* thread, ConstantPool* pool, int index);
+  static void    newscoped    (JavaThread* thread, ConstantPool* pool, int index);
   static void    newarray      (JavaThread* thread, BasicType type, jint size);
   static void    anewarray     (JavaThread* thread, ConstantPool* pool, int index, jint size);
   static void    multianewarray(JavaThread* thread, jint* first_size_address);
diff -r 8fd684b8c649 src/share/vm/interpreter/templateTable.cpp
--- a/src/share/vm/interpreter/templateTable.cpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/templateTable.cpp	Mon Nov 16 01:14:43 2015 +0000
@@ -476,6 +476,7 @@
   def(Bytecodes::_iinc                , ubcp|____|____|iswd, vtos, vtos, wide_iinc           ,  _           );
   def(Bytecodes::_ret                 , ubcp|disp|____|iswd, vtos, vtos, wide_ret            ,  _           );
   def(Bytecodes::_breakpoint          , ubcp|disp|clvm|____, vtos, vtos, _breakpoint         ,  _           );
+  def(Bytecodes::_newscoped           , ubcp|____|clvm|____, vtos, atos, newscoped           ,  f1_byte     );
 
   // JVM bytecodes
   def(Bytecodes::_fast_agetfield      , ubcp|____|____|____, atos, atos, fast_accessfield    ,  atos        );
diff -r 8fd684b8c649 src/share/vm/interpreter/templateTable.hpp
--- a/src/share/vm/interpreter/templateTable.hpp	Thu Nov 12 10:39:00 2015 -0800
+++ b/src/share/vm/interpreter/templateTable.hpp	Mon Nov 16 01:14:43 2015 +0000
@@ -296,6 +296,7 @@
   static void pop_and_check_object(Register obj);
 
   static void _new();
+  static void newscoped();
   static void newarray();
   static void anewarray();
   static void arraylength();
